geom_bar()
ggplot(datos_fito) +
aes(y = nombre_album) +
geom_bar(color = "red", fill = "black") +
labs(x = "Cantidad de canciones", y = "Álbum", title = "Cantidad de canciones por álbum - Fito Paez")
ggplot(datos_fito) +
aes(y = nombre_album) +
geom_bar(color = "black", fill = "red") +
labs(x = "Cantidad de canciones", y = "Álbum", title = "Cantidad de canciones por álbum - Fito Paez")
pie(datos_fito$nombre_album)
tabla <- table(datos_fito$nombre_album)
pie(datos_fito$nombre_album)
pie(tabla)
pie(tabla[1:5])
batplot(tabla[1:5])
barplot(tabla[1:5])
View(datos_fito)
ggplot(data = datos_fito) +
aes(x = nombre_album, fill = tipo_cancion) +
geom_bar(position = "fill") +
scale_y_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = nombre_album, fill = tipo_cancion) +
geom_bar(position = "fill") +
scale_y_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = nombre_album, fill = tipo_cancion) +
geom_bar(position = "fill") +
scale_x_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = nombre_album, fill = tipo_album) +
geom_bar(position = "fill") +
scale_x_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = tipo_album) +
geom_bar()
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar(position = "fill") +
scale_x_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = tipo_album) +
geom_bar(position = "fill") +
scale_x_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar() +
scale_x_continuous("Porcentaje", labels = scales::percent)
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar() +
tabla <- table(datos_fito$nombre_album)
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar() +
tabla <- table(datos_fito$nombre_album)
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar()
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar() +
theme_minimal
ggplot(data = datos_fito) +
aes(y = tipo_album, fill = tipo_album) +
geom_bar() +
theme_minimal()
# Defino funciones para calcular cada métrica
accuracy <- function(TP, FN, FP, TN) {
(TP + TN) / (TP + TN + FP + FN)
}
sensitivity <- function(TP, FN, FP, TN) {
TP / (TP + FN)
}
specificity <- function(TP, FN, FP, TN) {
TN / (TN + FP)
}
positive_predictive_value <- function(TP, FN, FP, TN) {
TP / (TP + FP)
}
negative_predictive_value <- function(TP, FN, FP, TN) {
TN / (TN + FN)
}
j_youden <- function(TP, FN, FP, TN) {
sensitivity(TP, FN, FP, TN) + specificity(TP, FN, FP, TN) - 1
}
markedness <- function(TP, FN, FP, TN) {
positive_predictive_value(TP, FN, FP, TN) + negative_predictive_value(TP, FN, FP, TN) - 1
}
f1_score <- function(TP, FN, FP, TN) {
2 * TP / (2 * TP + FP + FN)
}
cohen_kappa <- function(TP, FN, FP, TN) {
observed_agreement <- (TP + TN) / (TP + TN + FP + FN)
chance_agreement <- ((TP + FP) * (TP + FN) + (TN + FP) * (TN + FN)) / (TP + TN + FP + FN)^2
kappa <- (observed_agreement - chance_agreement) / (1 - chance_agreement)
kappa
}
matthews_correlation <- function(TP, FN, FP, TN) {
(TP * TN - FP * FN) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
}
# Defino las matrices de confusión para cada modelo (Orden: TP, FN, FP, TN)
modelo1 <- c(211, 27, 36, 156)
modelo2 <- c(112, 2, 26, 75)
modelo3 <- c(111, 3, 13, 88)
# Calculo las métricas para cada modelo
metricas_modelo1 <- c(
accuracy(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
sensitivity(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
specificity(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
positive_predictive_value(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
negative_predictive_value(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
j_youden(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
markedness(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
f1_score(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
cohen_kappa(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
matthews_correlation(modelo1[1], modelo1[2], modelo1[3], modelo1[4])
)
metricas_modelo2 <- c(
accuracy(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
sensitivity(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
specificity(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
positive_predictive_value(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
negative_predictive_value(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
j_youden(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
markedness(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
f1_score(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
cohen_kappa(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
matthews_correlation(modelo2[1], modelo2[2], modelo2[3], modelo2[4])
)
metricas_modelo3 <- c(
accuracy(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
sensitivity(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
specificity(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
positive_predictive_value(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
negative_predictive_value(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
j_youden(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
markedness(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
f1_score(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
cohen_kappa(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
matthews_correlation(modelo3[1], modelo3[2], modelo3[3], modelo3[4])
)
# Creo la tabla
knitr::kable(
cbind(
"Modelo" = c("AR", "R2", "R3"),
"EXA" = round(c(metricas_modelo1[1], metricas_modelo2[1], metricas_modelo3[1]), 3) * 100,
"SEN" = round(c(metricas_modelo1[2], metricas_modelo2[2], metricas_modelo3[2]), 3) * 100,
"ESP" = round(c(metricas_modelo1[3], metricas_modelo2[3], metricas_modelo3[3]), 3) * 100,
"VPP" = round(c(metricas_modelo1[4], metricas_modelo2[4], metricas_modelo3[4]), 3) * 100,
"VPN" = round(c(metricas_modelo1[5], metricas_modelo2[5], metricas_modelo3[5]), 3) * 100,
"J" = round(c(metricas_modelo1[6], metricas_modelo2[6], metricas_modelo3[6]), 3)* 100,
"INT" = round(c(metricas_modelo1[7], metricas_modelo2[7], metricas_modelo3[7]), 3)* 100,
"F1" = round(c(metricas_modelo1[8], metricas_modelo2[8], metricas_modelo3[8]), 3)* 100,
"K" = round(c(metricas_modelo1[9], metricas_modelo2[9], metricas_modelo3[9]), 3)* 100,
"MCC" = round(c(metricas_modelo1[10], metricas_modelo2[10], metricas_modelo3[10]), 3)* 100
)
)
## Mismo análisis pero con IC para las primeras cinco métricas
library(DescTools)
# Defino funciones para calcular cada métrica
accuracy <- function(TP, FN, FP, TN) {
IC <- round(BinomCI(TP + TN, TP + TN + FP + FN, conf.level = .95, method = "clopper-pearson"), 3)*100
paste0(IC[, 1], " [", IC[, 2], " ; ",IC[, 3], "]")
}
# Defino funciones para calcular cada métrica
accuracy <- function(TP, FN, FP, TN) {
IC <- round(BinomCI(TP + TN, TP + TN + FP + FN, conf.level = .95, method = "wald"), 3)*100
paste0(IC[, 1], " [", IC[, 2], " ; ",IC[, 3], "]")
}
sensitivity <- function(TP, FN, FP, TN) {
IC <- round(BinomCI(TP, TP + FN, conf.level = .95, method = "wald"), 3)*100
paste0(IC[, 1], " [", IC[, 2], " ; ",IC[, 3], "]")
}
specificity <- function(TP, FN, FP, TN) {
IC <- round(BinomCI(TN, TN + FP, conf.level = .95, method = "wald"), 3)*100
paste0(IC[, 1], " [", IC[, 2], " ; ",IC[, 3], "]")
}
positive_predictive_value <- function(TP, FN, FP, TN) {
IC <- round(BinomCI(TP, TP + FP, conf.level = .95, method = "wald"), 3)*100
paste0(IC[, 1], " [", IC[, 2], " ; ",IC[, 3], "]")
}
negative_predictive_value <- function(TP, FN, FP, TN) {
IC <- round(BinomCI(TN, TN + FN, conf.level = .95, method = "wald"), 3)*100
paste0(IC[, 1], " [", IC[, 2], " ; ",IC[, 3], "]")
}
# Calculo las métricas para cada modelo
metricas_modelo1 <- c(
accuracy(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
sensitivity(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
specificity(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
positive_predictive_value(modelo1[1], modelo1[2], modelo1[3], modelo1[4]),
negative_predictive_value(modelo1[1], modelo1[2], modelo1[3], modelo1[4])
)
metricas_modelo2 <- c(
accuracy(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
sensitivity(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
specificity(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
positive_predictive_value(modelo2[1], modelo2[2], modelo2[3], modelo2[4]),
negative_predictive_value(modelo2[1], modelo2[2], modelo2[3], modelo2[4])
)
metricas_modelo3 <- c(
accuracy(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
sensitivity(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
specificity(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
positive_predictive_value(modelo3[1], modelo3[2], modelo3[3], modelo3[4]),
negative_predictive_value(modelo3[1], modelo3[2], modelo3[3], modelo3[4])
)
# Creo la tabla
knitr::kable(
cbind(
"Modelo" = c("AR", "R2", "R3"),
"EXA" = c(metricas_modelo1[1], metricas_modelo2[1], metricas_modelo3[1]),
"SEN" = c(metricas_modelo1[2], metricas_modelo2[2], metricas_modelo3[2]),
"ESP" = c(metricas_modelo1[3], metricas_modelo2[3], metricas_modelo3[3]),
"VPP" = c(metricas_modelo1[4], metricas_modelo2[4], metricas_modelo3[4]),
"VPN" = c(metricas_modelo1[5], metricas_modelo2[5], metricas_modelo3[5])
)
)
library(MASS)
boston
Boston
boston <- Boston
modelo1 <- lm(log(medv) ~ lstat, data = Boston)
summary(modelo1)
summary(Boston$lstat)
modelo2 <- lm(log(medv) ~ (10+5*lstat), data = Boston)
modelo2 <- lm(log(medv) ~ I(10+5*lstat), data = Boston)
summary(modelo2)
Boston$lstat2 <- 10+5*Boston$lstat
modelo2prueba <- lm(log(medv) ~ lstat2, data = Boston)
summary(modelo2prueba)
summary(modelo1)
summary(modelo2)
coefficients(modelo1)
coefficients(modelo2)
is(modelo1$residuals == modelo2$residuals)
(modelo1$residuals == modelo2$residuals)
sum(modelo1$residuals == modelo2$residuals)
cbind(modelo1$residuals, modelo2$residuals)
cbind(modelo1$residuals, modelo2$residuals, modelo1$residuals == modelo2$residuals)
cbind(modelo1$residuals, modelo2$residuals)
# Conigna 3
modelo3 <- lm(log(medv) ~ lstat + I(10+5*lstat), data = Boston)
summary(modelo3)
# Conigna 3
modelo3 <- lm(log(medv) ~ lstat + lstat2, data = Boston)
summary(modelo3)
## Consigna 4
modelo4 <- lm(log(medv) ~ lstat + runif(), data = Boston)
## Consigna 4
modelo4 <- lm(log(medv) ~ lstat + runif(nrow(Boston)), data = Boston)
summary(modelo4)
modelo4 <- lm(log(medv) ~ lstat + runif(-.1, .1, nrow(Boston)), data = Boston)
modelo4 <- lm(log(medv) ~ lstat + runif(nrow(Boston), -.1, .1), data = Boston)
summary(modelo4)
Boston$U <- runif(nrow(Boston), -.1, .1)
modelo4 <- lm(log(medv) ~ lstat + U, data = Boston)
Boston$U <- runif(nrow(Boston), -.1, .1)
modelo4 <- lm(log(medv) ~ lstat + U, data = Boston)
summary(modelo4)
Boston$U <- runif(nrow(Boston), -.1, .1)
modelo4 <- lm(log(medv) ~ lstat + U, data = Boston)
summary(modelo4)
coefficients(modelo3)
set.seed(1974)
Boston$lstat3 <- runif(nrow(Boston), -.1, .1)
Boston$lstat4 <- Boston$lstat3 + 10
modelo4 <- lm(log(medv) ~ lstat + lstat3, data = Boston)
summary(modelo4)
Boston$lstat4 <- Boston$lstat3 + 10
modelo4 <- lm(log(medv) ~ lstat + lstat4, data = Boston)
summary(modelo4)
Boston$lstat4 <- Boston$lstat3 + 10
modelo4 <- lm(log(medv) ~ lstat + lstat4, data = Boston)
summary(modelo4)
set.seed(1974)
Boston$lstat3 <- runif(nrow(Boston), -.1, .1)
modelo4 <- lm(log(medv) ~ lstat + lstat3, data = Boston)
summary(modelo4)
Boston$lstat4 <- Boston$lstat3 + 10
modelo4 <- lm(log(medv) ~ lstat + lstat4, data = Boston)
summary(modelo4)
Boston$lstat4 <- Boston$lstat3
Boston$lstat4[1] <- Boston$lstat3[1] + 10
modelo4 <- lm(log(medv) ~ lstat + lstat4, data = Boston)
Boston$lstat4 <- Boston$lstat3
Boston$lstat4[1] <- Boston$lstat3[1] + 10
modelo4 <- lm(log(medv) ~ lstat + lstat4, data = Boston)
summary(modelo4)
set.seed(1974)
Boston$lstat3 <- runif(nrow(Boston), -.1, .1)
modelo4 <- lm(log(medv) ~ lstat + lstat3, data = Boston)
summary(modelo4)
Boston$lstat4 <- Boston$lstat3
Boston$lstat4[1] <- Boston$lstat3[1] + 10
modelo4 <- lm(log(medv) ~ lstat + lstat4, data = Boston)
summary(modelo4)
View(Boston)
library(car)
modelo_lstat  <- lm(log(medv) ~ lstat , data = Boston)
modelo_lstat3 <- lm(log(medv) ~ lstat3, data = Boston)
modelo_lstat4 <- lm(log(medv) ~ lstat4, data = Boston)
vif(c(modelo_lstat, modelo_lstat3, modelo_lstat4))
modelo_lstat  <- lm(log(medv) ~ lstat , data = Boston)
modelo_lstat3 <- lm(log(medv) ~ lstat3, data = Boston)
modelo_lstat4 <- lm(log(medv) ~ lstat4, data = Boston)
vif(modelo_lstat )
modelo6  <- lm(log(medv) ~ lstat + lstat3 + lstat4, data = Boston)
vif(modelo6)
# Modelos
iris
# Modelos
modelo1 <- lm(Sepal.Length ~ Sepal.Width, data = iris)
modelo2 <- lm(Sepal.Length ~ Petal.Length, data = iris)
modelo3 <- lm(Sepal.Length ~ Petal.Width, data = iris)
modelo4 <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)
modelo5 <- lm(Sepal.Length ~ Sepal.Width + Petal.Width, data = iris)
modelo6 <- lm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris)
modelo7 <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris)
sum(modelo1$resudiuals^2)
sum(modelo1$residuals^2)
summary(modelo1)
coefficients(modelo7)-1
length(coefficients(modelo7))
length(coefficients(modelo7))-1
sigma2 <- sum(modelo7$residuals^2) / (nrow(iris) - length(coefficients(modelo7))-1)
sigma
sigma2
sum(modelo1$residuals^2) / sigma2 + 2*(length(coefficients(modelo7))-1) - nrow(iris)
install.packages("olssrr")
install.packages("olsrr")
ols_mallows_cp(modelo1, modelo7)
library(olsrr)
ols_mallows_cp(modelo1, modelo7)
cp <- function(modelo, modelofull, data) {
SCE <- sum(modelo$residuals*modelo$residuals)
sigma2 <- sum(modelofull$residuals^2) / (nrow(data) - length(coefficients(modelofull))-1)
p <- length(coefficients(modelo))-1
n <- nrow(data)
Cp <- SCE / sigma2 + 2*p - n
paste0("Cp: ", Cp)
}
cp(modelo1, modelo7, iris)
paste0("Cp: ", round(Cp, 3))
cp <- function(modelo, modelofull, data) {
SCE <- sum(modelo$residuals*modelo$residuals)
sigma2 <- sum(modelofull$residuals^2) / (nrow(data) - length(coefficients(modelofull))-1)
p <- length(coefficients(modelo))-1
n <- nrow(data)
Cp <- SCE / sigma2 + 2*p - n
paste0("Cp: ", round(Cp, 3))
}
cp(modelo1, modelo7, iris)
cp(modelo1, modelo7, iris)
cp(modelo2, modelo7, iris)
cp(modelo3, modelo7, iris)
cp(modelo4, modelo7, iris)
cp(modelo5, modelo7, iris)
cp(modelo6, modelo7, iris)
cp(modelo7, modelo7, iris)
cme(modelo7)
mse(modelo7)
MSE(modelo7)
# Modelos
modelo1 <- lm(Sepal.Length ~ Sepal.Width, data = iris)
modelo2 <- lm(Sepal.Length ~ Petal.Length, data = iris)
cp <- function(modelo, modelofull, data) {
SCE <- sum(modelo$residuals*modelo$residuals)
sigma2 <- sum(modelofull$residuals^2) / (nrow(data) - length(coefficients(modelofull)))
p <- length(coefficients(modelo))
n <- nrow(data)
Cp <- SCE / sigma2 + 2*p - n
paste0("Cp: ", round(Cp, 3))
}
cp(modelo1, modelo7, iris)
cp(modelo2, modelo7, iris)
cp(modelo3, modelo7, iris)
cp(modelo4, modelo7, iris)
cp(modelo5, modelo7, iris)
cp(modelo6, modelo7, iris)
cp(modelo7, modelo7, iris)
7777/1830
7777+1830
7777+1830-9571
library(survival)
data <- rotterdam %>%
filter(year == 1991)
library(tidyverse)
data <- rotterdam %>%
filter(year == 1991)
survdiff(Surv(ytime, death) ~ chemo, data = data)
View(data)
survdiff(Surv(dtime, death) ~ chemo, data = data)
summary(survdiff(Surv(dtime, death) ~ chemo, data = data))
survdiff(Surv(dtime, death) ~ chemo, data = data)
survdiff(Surv(dtime, death) ~ chemo + strata(grade), data = data)
tet$n
test <- survdiff(Surv(dtime, death) ~ chemo + strata(grades), data = data)
test <- survdiff(Surv(dtime, death) ~ chemo + strata(grade), data = data)
test$n
test$obs
test$exp
test_lr <- survdiff(Surv(dtime, death) ~ chemo, data = data)
test_st <- survdiff(Surv(dtime, death) ~ chemo + strata(grade), data = data)
test_lr
test_lr$pvalue
qchisq(2.78, 1, lower.tail = F)
pchisq(2.78, 1, lower.tail = F)
test_st
test_lr
test_st
228-60
51-19
228*79/279
228*200/279
51*79/279
51*200/279
obs <- (60, 168, 19, 32)
obs <- c(60, 168, 19, 32)
exp <- c(64.56, 163.44, 14.44, 36.56)
sum((obs-exp)^2/exp^2)
test_lr$chisq
sum((obs-exp)^2/exp)
test_lr
test_lr$obs
## Librerías
library(tidyverse)  # Manipular datos
library(readxl)     # Importar archivo .xlsx
library(rpart)      # Aplicar árboles de decisión
library(rpart.plot) # Graficar árboles de decisión
library(caret)      # Usar función train()
## Importación del dataset
setwd("C:/Users/Victorio/Desktop/Viko/Academia/UNR - Licenciatura en Estadistica/Tesina/Ap 1 - Pistachos/Pistachio_Image_Dataset")
pist <- read_xlsx("Pistachio_28_Features_Dataset.xlsx") %>%
mutate(Class = case_when(
Class == "Kirmizi_Pistachio" ~ "Kirmizi",
Class == "Siirt_Pistachio" ~ "Siirt"
)
)
## Seteo de semilla para obtener resultados reproducibles
set.seed(7777777)
## División de datos en train y test para árbol de decisión (misma división que en Tree.R)
samp.80.20 <- sample(1 : nrow(pist), size = round(0.8 * nrow(pist)))
## División de datos en test y val para redes
pist.train <- pist[samp.80.20, ]
pist.test  <- pist[-samp.80.20, ]
dim(pist.train)
dim(pist.test)
## Ajuste y gráfica del árbol (modelo maximal)
pist.cart <- rpart(
as.factor(Class) ~ .,     # Incluyo todas las variables que tengo
control = rpart.control(
cp = 0,                 # Parámetro de complejidad (en 0 es el modelo maximal)
minbucket = 25          # Número mínimo de observaciones que puede quedar en cada nodo terminal
),
data = pist.train
)
rpart.plot(pist.cart,
extra = 100,
digits = 3,
tweak = 1.5,
box.palette = "Gn",
shadow.col = "darkgray")
# Opción 1: se imprimen los cp para ver cuál usar
printcp(pist.cart, digits = 3)
plotcp()
plotcp(pist.cart, upper = "splits")
plotcp(pist.cart, upper = "splits")
model2$results
## Seteo de semilla para obtener resultados reproducibles
set.seed(7777777)
## División de datos en train y test para árbol de decisión (misma división que en Tree.R)
samp.80.20 <- sample(1 : nrow(pist), size = round(0.8 * nrow(pist)))
## División de datos en test y val para redes
pist.train <- pist[samp.80.20, ]
pist.test  <- pist[-samp.80.20, ]
dim(pist.train)
dim(pist.test)
## Ajuste y gráfica del árbol (modelo maximal)
pist.cart <- rpart(
as.factor(Class) ~ .,     # Incluyo todas las variables que tengo
control = rpart.control(
cp = 0,                 # Parámetro de complejidad (en 0 es el modelo maximal)
minbucket = 25          # Número mínimo de observaciones que puede quedar en cada nodo terminal
),
data = pist.train
)
rpart.plot(pist.cart,
extra = 100,
digits = 3,
tweak = 1.5,
box.palette = "Gn",
shadow.col = "darkgray")
# Opción 1: se imprimen los cp para ver cuál usar
printcp(pist.cart, digits = 3)
plotcp(pist.cart, upper = "splits")
# Opción 2: validación cruzada para encontrar el óptimo
model2 <- train(
Class ~., data = pist.train, method = "rpart",
trControl = trainControl("cv", number = 10),
tuneLength = 10
)
model2$results
model2$bestTune
plot(model2$results)
plot(model2)
plot(model2, xlim = c(,0 0.05))
plot(model2, xlim = c(0, 0.05))
vline(x = 0.005)
plot(model2, xlim = c(0, 0.05))+
vline(x = 0.005)
